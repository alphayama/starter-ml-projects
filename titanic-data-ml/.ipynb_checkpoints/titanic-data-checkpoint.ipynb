{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict if a passenger survived the Titanic incident or not.\n",
    "\n",
    "1. **Data:** I will be using Age,Pclass,Sex,Sibsp,Parch and Fare(only in some cases) as data\n",
    "2. **Label:** Survived will be the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 csv files:<br>\n",
    "- train.csv: The training dataset with both data and corresponding label<br>\n",
    "- test.csv: The test dataset with data only<br>\n",
    "- gender_submission.csv: This dataset contains whether the passenger survived or not ie. the label</list>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train='../msit_ml_classwork/MSIT_ML_CLASS/datasets/titanic/train.csv'\n",
    "path_test='../msit_ml_classwork/MSIT_ML_CLASS/datasets/titanic/test.csv'\n",
    "path_res='../msit_ml_classwork/MSIT_ML_CLASS/datasets/titanic/gender_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic=pd.read_csv(path_train)\n",
    "testset=pd.read_csv(path_test)\n",
    "results=pd.read_csv(path_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping cabin\n",
    "\n",
    " I am dropping cabin because it has a lot of NULL values.<br>\n",
    " Since it is not useful in any way nor its null values can be replaced, it is not a useful piece of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic=titanic.drop(['Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age is a crucial piece of data.<br>\n",
    "It has a significant amount of null values. <br>\n",
    "<br><br>\n",
    "I'll be removing the null values using either of the following methods:<br>\n",
    "1. Using Imputer()\n",
    "2. Separating salutation from the name and finding mean age for each salutation. Then this mean value will be assigned to the rows having NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "titanic[titanic['Age'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=list(titanic['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salut=[i.split(',')[-1].split('.')[0][1:] for i in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=list(testset['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salut_test=[i.split(',')[-1].split('.')[0][1:] for i in name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data and label DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am separating data and labels into titanic_knn_X and titanic_knn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_knn_X=titanic.drop(['PassengerId','Survived','Name','Ticket'],axis=1)\n",
    "titanic_knn_y=titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_knn_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (Train split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighbors method is being applied to get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_knn_X=pd.get_dummies(titanic_knn_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_knn_X=titanic_knn_X.drop(['Sex_male','Embarked_S'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "scale=StandardScaler()\n",
    "imp=Imputer(missing_values = \"NaN\", strategy = \"mean\",axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(titanic_knn_X,titanic_knn_y,test_size=0.125,random_state=29)\n",
    "\n",
    "score_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20):\n",
    "    knn=KNeighborsClassifier(n_neighbors = i)\n",
    "    steps=[('imp',imp),\n",
    "       ('scale',scale),\n",
    "      ('clf',knn)]\n",
    "    pipeline=Pipeline(steps)\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    score_list.append(pipeline.score(X_test,y_test))\n",
    "print(max(score_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xticks(range(1,20))\n",
    "plt.plot(np.arange(1,20),score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (Train split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin=LinearRegression()\n",
    "\n",
    "pipeline=Pipeline([('imp',imp),('scale',scale),('linreg',lin)])\n",
    "pipeline.fit(X_train,y_train)\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression(Train split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrg=LogisticRegression()\n",
    "pipeline=Pipeline([('imp',imp),('scale',scale),('logreg',lrg)])\n",
    "pipeline.fit(X_train,y_train)\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree=DecisionTreeClassifier(random_state=29,max_depth=60,criterion='gini')\n",
    "imp=Imputer(missing_values = \"NaN\", strategy = \"most_frequent\",axis=0)\n",
    "\n",
    "\n",
    "pipeline=Pipeline([('imp',imp),('scale',scale),('clf',dtree)])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "pipeline.score(X_test,y_test)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=Imputer(missing_values = \"NaN\", strategy = \"mean\",axis=0)\n",
    "\n",
    "\n",
    "pipeline=Pipeline([('imp',imp),('scale',scale),('clf',dtree)])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=Imputer(missing_values = \"NaN\", strategy = \"median\",axis=0)\n",
    "\n",
    "\n",
    "pipeline=Pipeline([('imp',imp),('scale',scale),('clf',dtree)])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data and labels for method-2 for replacing NaN values in Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created two lists: **salut** and **salut_test** which contain the salutations from the names.<br>\n",
    "In the training and testing datasets, I'm adding a new column **'Salut'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titanic['Salut']=salut\n",
    "testset['Salut']=salut_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "titanic.groupby('Salut')['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salut_mean_dict=titanic.groupby('Salut')['Age'].mean().to_dict()\n",
    "salut_dict_test=testset.groupby('Salut')['Age'].mean().to_dict()\n",
    "salut_dict_test['Ms']=21.7\n",
    "salut_dict_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing NaN values with mean age for each salutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age']=titanic.apply(lambda row: salut_mean_dict[row['Salut']] if np.isnan(row['Age']) else row['Age'],axis=1 )\n",
    "testset['Age']=testset.apply(lambda row: salut_dict_test[row['Salut']] if np.isnan(row['Age']) else row['Age'],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic=titanic.drop('Salut',axis=1)\n",
    "titanic_X=titanic.drop(['PassengerId','Survived','Name','Ticket','Cabin','Fare'],axis=1)\n",
    "titanic_y=titanic['Survived']\n",
    "titanic_X=pd.get_dummies(titanic_X)\n",
    "titanic_X=titanic_X.drop(['Sex_male','Embarked_S'],axis=1)\n",
    "testset=testset.drop('Salut',axis=1)\n",
    "testset_X=testset.drop(['PassengerId','Name','Ticket','Cabin','Fare'],axis=1)\n",
    "testset_y=results['Survived']\n",
    "testset_X=pd.get_dummies(testset_X)\n",
    "testset_X=testset_X.drop(['Sex_male','Embarked_S'],axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(titanic_X,titanic_y,test_size=0.125,random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "titanic_X.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2=[]\n",
    "\n",
    "xg_clf=xgb.XGBClassifier(objective='reg:logistic',n_estimators=8,seed=29,max_depth= 90)\n",
    "xg_clf.fit(X_train,y_train)\n",
    "predict=xg_clf.predict(X_test)\n",
    "score2.append(float(np.sum(predict==y_test))/y_test.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximum Accuracy(train split):',max(score2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score3=[]\n",
    "\n",
    "xg_clf=xgb.XGBClassifier(objective='reg:logistic',n_estimators=19,seed=29,max_depth=50,gamma=0.1)\n",
    "xg_clf.fit(titanic_X,titanic_y)\n",
    "predict=xg_clf.predict(testset_X)\n",
    "score3.append(float(np.sum(predict==testset_y))/testset_y.shape[0])\n",
    "\n",
    "\n",
    "print('Maximum Accuracy(Final):',max(score3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with LabelEncoder and OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "\n",
    "category_mask=(titanic_X.dtypes=='object')\n",
    "category_columns=titanic_X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb=titanic_X\n",
    "data_xgb[category_columns]=data_xgb[category_columns].apply(lambda x:le.fit_transform(x))\n",
    "label_xgb=titanic_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[\n",
    "    ('ohe',OneHotEncoder(sparse=True,categorical_features=category_mask)),\n",
    "    ('clf',LinearRegression())\n",
    "]\n",
    "\n",
    "pipeline=Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy=cross_val_score(pipeline,X=data_xgb,y=label_xgb,cv=10)\n",
    "print('Accuracy(XGBoost:le/ohe:LinReg):',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mask=(testset_X.dtypes=='object')\n",
    "category_columns=testset_X.columns.tolist()\n",
    "\n",
    "data_xgb=testset_X\n",
    "data_xgb[category_columns]=data_xgb[category_columns].apply(lambda x:le.fit_transform(x))\n",
    "label_xgb=testset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[\n",
    "    ('ohe',OneHotEncoder(sparse=True,categorical_features=category_mask)),\n",
    "    ('clf',LinearRegression())\n",
    "]\n",
    "\n",
    "pipeline=Pipeline(steps)\n",
    "pipeline.fit(titanic_X,titanic_y)\n",
    "pipeline.score(testset_X,testset_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[\n",
    "    ('ohe',OneHotEncoder(sparse=True,categorical_features=category_mask)),\n",
    "    ('clf',LogisticRegression())\n",
    "]\n",
    "\n",
    "pipeline=Pipeline(steps)\n",
    "\n",
    "accuracy=cross_val_score(pipeline,X=data_xgb,y=label_xgb,cv=20)\n",
    "print('Accuracy(XGBoost:le/ohe:LinReg):',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_clf=RandomForestClassifier(n_estimators=73,max_depth=80,random_state=29)\n",
    "r_clf.fit(X_train,y_train)\n",
    "r_clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_clf=RandomForestClassifier(n_estimators=8,max_depth=90,random_state=29,criterion='entropy' )\n",
    "r_clf.fit(X_train,y_train)\n",
    "r_clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_clf=RandomForestClassifier(n_estimators=112,max_depth=80,random_state=29,min_samples_split=0.1 )\n",
    "r_clf.fit(X_train,y_train)\n",
    "r_clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_clf=RandomForestClassifier(n_estimators=10,max_depth=90,random_state=29,criterion='entropy',min_samples_split=0.133)\n",
    "r_clf.fit(X_train,y_train)\n",
    "r_clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_clf=RandomForestClassifier(n_estimators=90,max_depth=70,random_state=29)\n",
    "r_clf.fit(titanic_X,titanic_y)\n",
    "r_clf.score(testset_X,testset_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_clf=RandomForestClassifier(n_estimators=112,max_depth=80,random_state=29,min_samples_split=0.1 )\n",
    "r_clf.fit(titanic_X,titanic_y)\n",
    "r_clf.score(testset_X,testset_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9282296650717703"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_clf=RandomForestClassifier(n_estimators=10,max_depth=90,random_state=29,criterion='entropy',min_samples_split=0.133)\n",
    "r_clf.fit(titanic_X,titanic_y)\n",
    "r_clf.score(testset_X,testset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492822966507177"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_clf=RandomForestClassifier(n_estimators=50,max_depth=90,random_state=29,criterion='entropy' )\n",
    "r_clf.fit(titanic_X,titanic_y)\n",
    "r_clf.score(testset_X,testset_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "score:  0.43153642378623713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "step_gscv=[\n",
    "    ('ohe',OneHotEncoder(sparse=True,categorical_features=category_mask)),\n",
    "    ('clf',xgb.XGBRegressor())\n",
    "]\n",
    "\n",
    "clf_param_grid={\n",
    "    'clf__max_depth':[80,90,100],\n",
    "    'clf__learning_rate':[0.052]\n",
    "}\n",
    "\n",
    "gscv_clf=Pipeline(step_gscv)\n",
    "estimator=GridSearchCV(gscv_clf,param_grid=clf_param_grid,cv=5,verbose=1,scoring='neg_mean_squared_error')\n",
    "estimator.fit(titanic_X,titanic_y)\n",
    "print('score: ',np.sqrt(-1*estimator.score(testset_X,testset_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel='poly' didn't yield a result. I had to restart the kernel:("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(titanic_X,titanic_y,test_size=0.125,random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC()\n",
    "pipeline=Pipeline([('imp',imp),('scale',scale),('clf',svm_clf)])\n",
    "pipeline.fit(X_train,y_train)\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7946428571428571"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC()\n",
    "\n",
    "svm_clf.fit(X_train,y_train)\n",
    "svm_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='linear',random_state=29)\n",
    "\n",
    "svm_clf.fit(X_train,y_train)\n",
    "svm_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_clf=svm.SVC(kernel='poly',random_state=29)\n",
    "\n",
    "# svm_clf.fit(X_train,y_train)\n",
    "# svm_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7946428571428571"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='rbf',C=1e9,random_state=29)\n",
    "\n",
    "svm_clf.fit(X_train,y_train)\n",
    "svm_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6071428571428571"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='sigmoid',C=1e20,random_state=29)\n",
    "\n",
    "svm_clf.fit(X_train,y_train)\n",
    "svm_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='rbf',random_state=29)\n",
    "pipeline=Pipeline([('imp',imp),('scale',scale),('clf',svm_clf)])\n",
    "pipeline.fit(X_train,y_train)\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253588516746412"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC()\n",
    "\n",
    "svm_clf.fit(titanic_X,titanic_y)\n",
    "svm_clf.score(testset_X,testset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='linear',random_state=29)\n",
    "\n",
    "svm_clf.fit(titanic_X,titanic_y)\n",
    "svm_clf.score(testset_X,testset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253588516746412"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='rbf',random_state=29)\n",
    "\n",
    "svm_clf.fit(titanic_X,titanic_y)\n",
    "svm_clf.score(testset_X,testset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='sigmoid')\n",
    "\n",
    "svm_clf.fit(titanic_X,titanic_y)\n",
    "svm_clf.score(testset_X,testset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325358851674641"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel='rbf',random_state=29,gamma=0.062)\n",
    "\n",
    "svm_clf.fit(titanic_X,titanic_y)\n",
    "svm_clf.score(testset_X,testset_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying Random Forest classifier, I obtained max. score of **94.7%**<br>\n",
    "Most scores are in range of 80-90%.<br>\n",
    "Despite tuning, more accuracy could not be achieved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
